{
	"name": "PIPE_snowflake_query",
	"properties": {
		"activities": [
			{
				"name": "Script1",
				"type": "Script",
				"dependsOn": [],
				"policy": {
					"timeout": "0.12:00:00",
					"retry": 0,
					"retryIntervalInSeconds": 30,
					"secureOutput": false,
					"secureInput": false
				},
				"userProperties": [],
				"linkedServiceName": {
					"referenceName": "adfadbplt001lssnfkpltdnaload",
					"type": "LinkedServiceReference"
				},
				"typeProperties": {
					"scripts": [
						{
							"type": "Query",
							"text": "CREATE OR REPLACE PROCEDURE ASPSDL_RAW.SHILLA_TEST(Param array)\r\nRETURNS VARCHAR(16777216)\r\nLANGUAGE PYTHON\r\nRUNTIME_VERSION = '3.8'\r\nPACKAGES = ('snowflake-snowpark-python')\r\nHANDLER = 'main'\r\nEXECUTE AS CALLER\r\nAS \r\n$$\r\n# The Snowpark package is required for Python Worksheets. \r\n# You can add more packages by selecting them using the Packages control and then importing them.\r\n\r\nimport snowflake.snowpark as snowpark\r\nfrom snowflake.snowpark.types import IntegerType, StringType, StructType, StructField\r\nfrom snowflake.snowpark.functions import col\r\nimport pandas as pd\r\n\r\ndef main(session: snowpark.Session, Param): \r\n    # Your code goes here, inside the \"main\" handler.\r\n    df_schema=StructType([\r\n        StructField(\"Brand\",StringType()),\r\n        StructField(\"SKU\",StringType()),\r\n        StructField(\"Desc\",StringType()),\r\n        StructField(\"Ref_No\",StringType()),\r\n        StructField(\"EAN_UPC\",StringType()),\r\n        StructField(\"Color\",StringType()),\r\n        StructField(\"Sold_Qty1\",StringType()),\r\n        StructField(\"Gross_Sales1\",StringType()),\r\n        StructField(\"Sold_Qty2\",StringType()),\r\n        StructField(\"Gross_Sales2\",StringType()),\r\n        StructField(\"Sold_Qty3\",StringType()),\r\n        StructField(\"Gross_Sales3\",StringType()),\r\n        StructField(\"Sold_Qty4\",StringType()),\r\n        StructField(\"Gross_Sales4\",StringType()),\r\n        StructField(\"Sold_Qty5\",StringType()),\r\n        StructField(\"Gross_Sales5\",StringType())\r\n        ])\r\n    \r\n    df = session.read\\\r\n    .schema(df_schema)\\\r\n    .option(\"skip_header\",2)\\\r\n    .csv(\"@\"+Param[1]+\".\"+Param[2]+Param[3]+\"/\"+Param[0])\r\n    df_filter=df.filter(col(\"Brand\") != 'Total')\r\n    print(\"---------------Input DataFram ------------------------------------\")\r\n    print(\"snowpark dataframe\")\r\n    df_filter.show(100)\r\n    pandas_df=df_filter.to_pandas()\r\n    pd.set_option('display.max_columns', None)\r\n    # print(\"pandas df \")\r\n    # print(pandas_df)\r\n\r\n    #---------------------------Transformation logic ------------------------------\r\n    # Create a list of location names\r\n    locations = [\"Terminal 1\", \"Terminal 2\", \"Terminal 3\", \"Terminal 4\", \"IshopChangi\"]\r\n\r\n    # Create an empty list to store the transformed rows\r\n    transformed_rows = []\r\n\r\n    for index, row in pandas_df.iterrows():\r\n    # Iterate over each location\r\n        for location in locations:\r\n            # Create a copy of the original row\r\n            new_row = row.copy()\r\n            \r\n            # Add location-specific information\r\n            new_row[\"location_name\"] = location\r\n            new_row[\"sls_qty\"] = row[f\"SOLD_QTY{locations.index(location) + 1}\"]\r\n            new_row[\"sls_amt\"] = row[f\"GROSS_SALES{locations.index(location) + 1}\"]\r\n            \r\n            # Add retailer_name, year_month, and file_name\r\n            new_row[\"retailer_name\"] = Param[0].split('_')[0]\r\n            new_row[\"year_month\"] = Param[0].split('_')[1].split('.')[0]\r\n            new_row[\"file_name\"] = Param[0].split('.')[0]+\".xlsx\"\r\n            \r\n            # Append the transformed row to the list\r\n            transformed_rows.append(new_row)\r\n\r\n    # Create a new DataFrame from the transformed rows\r\n    transformed_df = pd.DataFrame(transformed_rows)\r\n    \r\n    # Display the transformed DataFrame\r\n    # print(\"transformdf \")\r\n    # print(transformed_df[[\"retailer_name\",\"year_month\",\"BRAND\",\"SKU\",\"DESC\",\"REF_NO\",\"EAN_UPC\",\"COLOR\",\"location_name\",\"sls_qty\",\"sls_amt\"]])\r\n    final_df=transformed_df[[\"retailer_name\",\"year_month\",\"BRAND\",\"SKU\",\"DESC\",\"REF_NO\",\"EAN_UPC\",\"COLOR\",\"location_name\",\"sls_qty\",\"sls_amt\",\"file_name\"]]\r\n\r\n\r\n    #---------------------------end of tranformation logic ------------------------\r\n    final_df_schema=StructType([\r\n        StructField(\"retailer_name\",StringType()),\r\n        StructField(\"year_month\",StringType()),\r\n        StructField(\"BRAND\",StringType()),\r\n        StructField(\"SKU\",StringType()),\r\n        StructField(\"DESC\",StringType()),\r\n        StructField(\"EAN_UPC\",StringType()),\r\n        StructField(\"COLOR\",StringType()),\r\n        StructField(\"location_name\",StringType()),\r\n        StructField(\"sls_qty\",StringType()),\r\n        StructField(\"sls_amt\",StringType()),\r\n        StructField(\"file_name\",StringType())\r\n        ])\r\n    \r\n    snowdf=session.create_dataframe(final_df,final_df_schema)\r\n    print(\"showpark dataframe\")\r\n    snowdf.write.copy_into_location(\"@\"+Param[1]+\".\"+Param[2]+Param[3]+\"/success/\"+Param[0],file_format_type=\"csv\",header=True,OVERWRITE=True)\r\n    snowdf.write.mode(\"overwrite\").saveAsTable(Param[1]+\".\"+Param[4])\r\n\r\n                               \r\n    return 'completed with this input ' + Param[0]\r\n$$\r\n"
						}
					],
					"scriptBlockExecutionTimeout": "02:00:00"
				}
			}
		],
		"variables": {
			"countQueryRedshift": {
				"type": "String"
			},
			"countQuerySnowflake": {
				"type": "String"
			}
		},
		"folder": {
			"name": "Historical_Data_migration_redshift_snowflake"
		},
		"annotations": []
	}
}